{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Cleanup\n",
    "data = pd.read_csv(\"exoplanet_data.csv\")\n",
    "\n",
    "# Drop null columns\n",
    "data = data.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop null rows\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert dtypes of int64 to float64\n",
    "for column, content in data.items():\n",
    "    if data[column].dtype == 'int64':\n",
    "        data = data.astype({column: 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-processing\n",
    "# Assign data to X and y\n",
    "X = data.drop(\"koi_disposition\", axis=1)\n",
    "y = data[\"koi_disposition\"]\n",
    "\n",
    "# Split data into training and testing groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X values\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 100.0 %\n",
      "Testing Data Score: 89.874 %\n"
     ]
    }
   ],
   "source": [
    "## Build the Model\n",
    "## Train the Model\n",
    "model_1 = RandomForestClassifier(n_estimators=200)\n",
    "model_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "model_1_training_score = round(model_1.score(X_train_scaled, y_train)*100,3)\n",
    "base_accuracy = round(model_1.score(X_test_scaled, y_test)*100,3)\n",
    "\n",
    "print(f\"Training Data Score: {model_1_training_score} %\")\n",
    "print(f\"Testing Data Score: {base_accuracy} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <td>0.109319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <td>0.090579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <td>0.067705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_model_snr</th>\n",
       "      <td>0.054857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_prad</th>\n",
       "      <td>0.047701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <td>0.035001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <td>0.034964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <td>0.033589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <td>0.032374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <td>0.029620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <td>0.029080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <td>0.027545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_duration</th>\n",
       "      <td>0.025682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_period</th>\n",
       "      <td>0.023287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <td>0.022792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <td>0.022633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_depth</th>\n",
       "      <td>0.022208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <td>0.019560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_period_err2</th>\n",
       "      <td>0.018819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_period_err1</th>\n",
       "      <td>0.018460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_impact</th>\n",
       "      <td>0.017066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_teq</th>\n",
       "      <td>0.015917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <td>0.015116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <td>0.014345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_time0bk</th>\n",
       "      <td>0.014234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_insol</th>\n",
       "      <td>0.014040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <td>0.013880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ra</th>\n",
       "      <td>0.013328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <td>0.011866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_kepmag</th>\n",
       "      <td>0.011509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <td>0.011062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <td>0.010893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dec</th>\n",
       "      <td>0.010739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <td>0.010563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_steff</th>\n",
       "      <td>0.009940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_srad</th>\n",
       "      <td>0.009560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_slogg</th>\n",
       "      <td>0.009480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <td>0.009285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <td>0.008402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <td>0.003003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Feature                    \n",
       "koi_fpflag_co      0.109319\n",
       "koi_fpflag_nt      0.090579\n",
       "koi_fpflag_ss      0.067705\n",
       "koi_model_snr      0.054857\n",
       "koi_prad           0.047701\n",
       "koi_duration_err1  0.035001\n",
       "koi_steff_err1     0.034964\n",
       "koi_prad_err1      0.033589\n",
       "koi_fpflag_ec      0.032374\n",
       "koi_prad_err2      0.029620\n",
       "koi_duration_err2  0.029080\n",
       "koi_steff_err2     0.027545\n",
       "koi_duration       0.025682\n",
       "koi_period         0.023287\n",
       "koi_time0bk_err2   0.022792\n",
       "koi_time0bk_err1   0.022633\n",
       "koi_depth          0.022208\n",
       "koi_insol_err1     0.019560\n",
       "koi_period_err2    0.018819\n",
       "koi_period_err1    0.018460\n",
       "koi_impact         0.017066\n",
       "koi_teq            0.015917\n",
       "koi_depth_err1     0.015116\n",
       "koi_insol_err2     0.014345\n",
       "koi_time0bk        0.014234\n",
       "koi_insol          0.014040\n",
       "koi_depth_err2     0.013880\n",
       "ra                 0.013328\n",
       "koi_srad_err1      0.011866\n",
       "koi_kepmag         0.011509\n",
       "koi_slogg_err2     0.011062\n",
       "koi_impact_err1    0.010893\n",
       "dec                0.010739\n",
       "koi_impact_err2    0.010563\n",
       "koi_steff          0.009940\n",
       "koi_srad           0.009560\n",
       "koi_slogg          0.009480\n",
       "koi_slogg_err1     0.009285\n",
       "koi_srad_err2      0.008402\n",
       "koi_tce_plnt_num   0.003003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which features ought to be kept\n",
    "feature_names = X.columns.tolist()\n",
    "preSelected_features = sorted(zip(model_1.feature_importances_, feature_names), reverse=True)\n",
    "ranked_features = pd.DataFrame(preSelected_features, columns=['Score', 'Feature'])\n",
    "ranked_features = ranked_features.set_index('Feature')\n",
    "ranked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with Score < 0.011\n",
    "selected_features = []\n",
    "for tup in preSelected_features:\n",
    "    if tup[0] > 0.01:\n",
    "        selected_features.append(tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 100.0 %\n",
      "Testing Data Score: 90.217 %\n"
     ]
    }
   ],
   "source": [
    "# Use new data for all subsequent models\n",
    "## Assign new data to X \n",
    "X_train_select = X_train[selected_features]\n",
    "X_test_select = X_test[selected_features]\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train_select)\n",
    "X_train_scaled = X_scaler.transform(X_train_select)\n",
    "X_test_scaled = X_scaler.transform(X_test_select)\n",
    "\n",
    "## Train new model\n",
    "model_2 = RandomForestClassifier(n_estimators=200)\n",
    "model_2.fit(X_train_scaled, y_train)\n",
    "\n",
    "model_2_training_score = round(model_2.score(X_train_scaled, y_train)*100,3)\n",
    "select_features_accuracy = round(model_2.score(X_test_scaled, y_test)*100,3)\n",
    "\n",
    "print(f\"Training Data Score: {model_2_training_score} %\")\n",
    "print(f\"Testing Data Score: {select_features_accuracy} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 15.6min finished\n"
     ]
    }
   ],
   "source": [
    "## Model Tuning\n",
    "## Create the RandomSearchCV model\n",
    "model_3 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 600, 1200, 1400],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [14, 15, 16, 17, 18, None]\n",
    "}\n",
    "grid = GridSearchCV(model_3, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "\n",
    "# Train the model with GridSearch\n",
    "_ = grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Tuned Model\n",
    "## Tuned parameters\n",
    "max_features = grid.best_params_['max_features']\n",
    "n_estimators = grid.best_params_['n_estimators']\n",
    "max_depth = grid.best_params_['max_depth']\n",
    "criterion = 'entropy'\n",
    "\n",
    "# Tuned model\n",
    "tuned_model = RandomForestClassifier(max_features=max_features, n_estimators=n_estimators, \n",
    "                                     criterion=criterion, max_depth=max_depth, random_state=42)\n",
    "tuned_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "model_3_training_score = round(tuned_model.score(X_train_scaled, y_train)*100,3)\n",
    "tuned_accuracy = round(tuned_model.score(X_test_scaled, y_test)*100,3)\n",
    "\n",
    "print(f\"Training Data Score: {model_3_training_score} %\")\n",
    "print(f\"Testing Data Score: {tuned_accuracy} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Predictions\n",
    "predictions = tuned_model.predict(X_test_scaled)\n",
    "classifications = y_test.unique().tolist()\n",
    "\n",
    "prediction_actual = {\n",
    "    'Actual': y_test,\n",
    "    'Prediction': predictions\n",
    "}\n",
    "\n",
    "PA_df = pd.DataFrame(prediction_actual)\n",
    "PA_df = PA_df.set_index('Actual').reset_index()\n",
    "PA_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluations\n",
    "evaluations = {'': ['Base Model', 'Select Features Model', 'Tuned Model'],\n",
    "               'Accuracy': [f\"{base_accuracy}%\", f\"{select_features_accuracy}%\", f\"{tuned_accuracy}%\"]}\n",
    "\n",
    "evaluations_df = pd.DataFrame(evaluations)\n",
    "evaluations_df = evaluations_df.set_index('')\n",
    "\n",
    "evaluations_df.to_csv('RandomForestClassifier_eval.csv')\n",
    "evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'BestModel_RandomForest.sav'\n",
    "_ = joblib.dump(tuned_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
